{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5576057",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# IE 678 Deep Learning, University of Mannheim\n",
    "# Author: Rainer Gemulla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb2fe7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import base64\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "\n",
    "from IPython import get_ipython\n",
    "from util import nextplot\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312537a",
   "metadata": {},
   "source": [
    "# 1 Basic Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4af083",
   "metadata": {},
   "source": [
    "## 1a Manual search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf835413",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is the function we are going to optimize. Do not look at this function yet (e.g.,\n",
    "# do not decode the funciton body and do not evaluate it).\n",
    "@np.vectorize\n",
    "def f1(*args):\n",
    "    x = np.array(args)\n",
    "    return eval(\n",
    "        base64.b64decode(\n",
    "            b\"LW5wLnByb2QobnAuc3FydChucC5hYnMoeCkqMTApKm5wLnNpbih4KjEwKSk=\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377306c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This helper function plots a number of 2D inputs along with their value.\n",
    "def plotp(X, y):\n",
    "    if len(X.shape) != 2 or X.shape[1] != 2 or X.shape[0] != len(y):\n",
    "        raise ValueError\n",
    "\n",
    "    x1, x2 = X[:, 0], X[:, 1]\n",
    "    plot = plt.scatter(x1, x2, c=y, cmap=matplotlib.cm.coolwarm, s=500)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.xlim(-0.1, 1.1)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    for i in range(len(X)):\n",
    "        plt.text(\n",
    "            X[i, 0],\n",
    "            X[i, 1],\n",
    "            \"{:.1f}\".format(y[i]),\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            color=\"white\",\n",
    "        )\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd299d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nextplot()\n",
    "X = np.array(\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        # Add 11 more points, one by one. Note that you can hover your mouse over a\n",
    "        # region you'd like to explore to read of the corresponding coordinates.\n",
    "        # YOUR CODE HERE\n",
    "    ]\n",
    ")\n",
    "y = f1(X[:, 0], X[:, 1])\n",
    "plotp(X, y)\n",
    "print(f\"Your best trial so far is {np.min(y)} at {X[np.argmin(y),:]}\")\n",
    "print(f\"You have {12-len(X)} trials left.\")\n",
    "\n",
    "# ## 1b Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ca4b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After you did a), uncomment these lines to see the true minimum.\n",
    "# x_min = np.array(eval(base64.b64decode(b\"WzAuNzkxNywwLjc5MTdd\")))\n",
    "# print(f\"True minimum is {f1(*x_min)} at {x_min}.\")\n",
    "# print(f\"You found {np.min(y)} at {X[np.argmin(y),:]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d496c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot3d(f):\n",
    "    x1 = np.arange(0, 1, 0.01)\n",
    "    x2 = np.arange(0, 1, 0.01)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    z = f(x1, x2)\n",
    "    ax = plt.gcf().add_subplot(projection=\"3d\")\n",
    "    ax.plot_surface(x1, x2, z, cmap=matplotlib.cm.coolwarm)\n",
    "\n",
    "\n",
    "# After you did a), uncomment these lines to see the full function as 3d plot.\n",
    "# nextplot()\n",
    "# plot3d(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fab2a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotc(f):\n",
    "    x1 = np.arange(0, 1, 0.01)\n",
    "    x2 = np.arange(0, 1, 0.01)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    z = f(x1, x2)\n",
    "    plt.contour(x1, x2, z, cmap=matplotlib.cm.coolwarm)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "# After you did a), uncomment these lines to see the full function as contour plot.\n",
    "# nextplot()\n",
    "# plotc(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a05bd5",
   "metadata": {},
   "source": [
    "## 1c Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f6d13",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform grid search with 12 trials. You may use plotp as above to visualize the\n",
    "# results.\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d278c",
   "metadata": {},
   "source": [
    "## 1d Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49d000",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform a random search with 12 trials.\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014c1dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optional: Repeat using a Sobol sequence. You can generate Sobol trials as follows.\n",
    "from skopt.sampler import Sobol  # pip install scikit-optimize\n",
    "\n",
    "sobol = Sobol()\n",
    "sobol.generate([(0.0, 1.0), (0.0, 1.0)], 12)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a275e7e",
   "metadata": {},
   "source": [
    "# 2 Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e77978",
   "metadata": {},
   "source": [
    "## 2a Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cc267",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The class of kernels we use in this task. The kernel is a scaled version of an RBF\n",
    "# kernel. The argument \"fixed\" means that the kernel parameters (i.e., scale and\n",
    "# length_scale) should not be optimized when fitting a GP with this kernel later.\n",
    "def srbf(scale=1.0, length_scale=1.0, fixed=True):\n",
    "    if fixed:\n",
    "        return ConstantKernel(scale, constant_value_bounds=\"fixed\") * RBF(\n",
    "            length_scale, length_scale_bounds=\"fixed\"\n",
    "        )\n",
    "    else:\n",
    "        return ConstantKernel(scale) * RBF(length_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12821aaa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example kernels\n",
    "nextplot()\n",
    "x_all = np.linspace(-10, 10, 1000)\n",
    "for i, scale in enumerate([1, 2, 5]):\n",
    "    for j, length_scale in enumerate([0.3, 1, 3]):\n",
    "        kernel = srbf(scale, length_scale)\n",
    "        plt.plot(\n",
    "            x_all,\n",
    "            kernel(x_all.reshape(-1, 1), np.array([[0]])),\n",
    "            color=f\"C{j}\",\n",
    "            linestyle=[\"-\", \"--\", \":\"][i],\n",
    "            label=f\"s={scale}, ls={length_scale}\",\n",
    "        )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cc578",
   "metadata": {},
   "source": [
    "## 2b GP prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7348e65",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This creates a GP prior with the default kernel (which is srbf(1,1)).\n",
    "gp = GaussianProcessRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459e638",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot mean +- std_dev of a GP prior or posterior \n",
    "def plot_gp(gp):\n",
    "    x_all = np.linspace(0, 1, 1000)\n",
    "\n",
    "    # plot fit\n",
    "    yhat_all, yhat_all_std = gp.predict(x_all.reshape(-1, 1), return_std=True)\n",
    "    plt.plot(x_all, yhat_all, color=\"red\")\n",
    "    plt.fill_between(\n",
    "        x_all, yhat_all - yhat_all_std, yhat_all + yhat_all_std, color=\"orange\"\n",
    "    )\n",
    "\n",
    "nextplot()\n",
    "plot_gp(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f443c4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample from a GP.\n",
    "# Plot samples from a GP prior or posterior\n",
    "def plot_gp_samples(gp, n=100, alpha=0.5):\n",
    "    x_all = np.linspace(0, 1, 1000)\n",
    "    plt.plot(x_all, gp.sample_y(x_all.reshape(-1,1), n), alpha=alpha)\n",
    "\n",
    "nextplot()\n",
    "plot_gp_samples(gp, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8c52a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment with different kernels\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494ceeb",
   "metadata": {},
   "source": [
    "## 2c GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6112b06",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are working with this function. With your knowledge of the function, what would be\n",
    "# a suitable scale and length scale?\n",
    "def f2(x):\n",
    "    return np.sin((2.0 * x) ** 5.0) / (x + 1)\n",
    "\n",
    "def plot_f2():\n",
    "    # show function itself\n",
    "    x_all = np.linspace(0, 1, 1000)\n",
    "    plt.plot(x_all, f2(x_all))\n",
    "\n",
    "nextplot()\n",
    "plot_f2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dda9b7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the posterior distribution of GPR (here using the default kernel)\n",
    "x = np.linspace(0, 1, 3)\n",
    "y = f2(x)\n",
    "gp = GaussianProcessRegressor().fit(x.reshape(-1,1), y)\n",
    "\n",
    "nextplot()\n",
    "plot_f2()\n",
    "plt.plot(x,y, \"x\", color=\"black\")\n",
    "plot_gp(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1b653",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Samples of the posterior can be plotted similarly.\n",
    "nextplot()\n",
    "plot_f2()\n",
    "plt.plot(x,y, \"x\", color=\"black\")\n",
    "plot_gp_samples(gp, 50, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b13fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now use your estimated kernel parameters. Discuss.\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db897f",
   "metadata": {},
   "source": [
    "## 2d Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602ce29",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment with different kernels and number of examples.\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7656196",
   "metadata": {},
   "source": [
    "# 3 Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b88ae0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
